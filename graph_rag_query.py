#!/usr/bin/env python3
# coding: utf-8
"""
GraphRAG æŸ¥è¯¢å·¥å…·
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Chroma å‘é‡æ•°æ®åº“å’Œå…³ç³»æ•°æ®è¿›è¡Œè¯­ä¹‰æ£€ç´¢å’Œå›¾ç»“æ„æ¨ç†
"""

import os
import json
import logging
from typing import List, Dict, Optional, Any
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from dotenv import load_dotenv

# å¯¼å…¥ç»Ÿä¸€çš„åµŒå…¥æ¨¡å‹
from Model.EMBEDDING_MODEL import global_embeddings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    filename='graph_rag_query.log'
)
logger = logging.getLogger("graph_rag_query")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class GraphRAGQueryEngine:
    """GraphRAG æŸ¥è¯¢å¼•æ“ï¼Œç»“åˆå‘é‡æ£€ç´¢å’Œå›¾ç»“æ„æ¨ç†"""
    
    def __init__(self):
        """åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“"""
        # å‘é‡æ•°æ®åº“é…ç½®
        from config import config
        self.vector_db_path = config.VECTOR_DB_PATH
        os.makedirs(self.vector_db_path, exist_ok=True)
        
        # å…³ç³»æ•°æ®æ–‡ä»¶è·¯å¾„
        self.relations_file_path = "relations_data.json"
        
        # ä½¿ç”¨ç»Ÿä¸€çš„å…¨å±€åµŒå…¥æ¨¡å‹
        self.embeddings = global_embeddings
        
        # åŠ è½½å…³ç³»æ•°æ®
        self.relations_by_source = self._load_relations_data()
        
        # åŠ è½½ Chroma é›†åˆ
        self.vectorstore = self._load_chroma_collection()
        
        logger.info(f"GraphRAGQueryEngine åˆå§‹åŒ–æˆåŠŸï¼ˆä½¿ç”¨ç»Ÿä¸€æœ¬åœ°åµŒå…¥æ¨¡å‹ï¼Œå‘é‡æ•°æ®åº“: Chromaï¼‰")
    
    def _load_relations_data(self) -> Dict[int, List[Dict[str, Any]]]:
        """åŠ è½½å…³ç³»æ•°æ®ï¼ˆä¼˜åŒ–å¤§æ–‡ä»¶åŠ è½½ï¼‰"""
        try:
            import ijson
            relations = {}
            
            logger.info(f"å¼€å§‹åŠ è½½å…³ç³»æ•°æ®æ–‡ä»¶: {self.relations_file_path}")
            with open(self.relations_file_path, 'rb') as f:
                # ä½¿ç”¨ijsonæµå¼è¯»å–å¤§JSONæ–‡ä»¶
                objects = ijson.kvitems(f, '')
                for node_id_str, rels in objects:
                    node_id = int(node_id_str)
                    relations[node_id] = rels
            
            logger.info(f"æˆåŠŸåŠ è½½å…³ç³»æ•°æ®ï¼Œå…± {len(relations)} ä¸ªèŠ‚ç‚¹çš„å…³ç³»")
            return relations
        except FileNotFoundError:
            logger.error(f"å…³ç³»æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {self.relations_file_path}")
            return {}
    
    def _load_chroma_collection(self) -> Chroma:
        """åŠ è½½ Chroma é›†åˆ"""
        logger.info("åŠ è½½ Chroma é›†åˆ...")
        
        try:
            # å°è¯•ä»å·²æœ‰è·¯å¾„åŠ è½½é›†åˆ
            vectorstore = Chroma(
                persist_directory=self.vector_db_path,
                embedding_function=self.embeddings,
                collection_name="medical_graph"
            )
            
            # éªŒè¯é›†åˆæ˜¯å¦æœ‰æ•°æ®
            if vectorstore._collection.count() == 0:
                logger.warning(f"Chroma é›†åˆä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œ neo4j_to_chroma.py")
            
            logger.info(f"æˆåŠŸåŠ è½½ Chroma é›†åˆ")
            return vectorstore
        except Exception as e:
            logger.error(f"åŠ è½½ Chroma é›†åˆå¤±è´¥: {str(e)}")
            raise Exception(f"Chroma é›†åˆåŠ è½½å¤±è´¥ï¼Œè¯·å…ˆè¿è¡Œ neo4j_to_chroma.py")
    
    def vector_search(self, query_text: str, top_k: int = 3, node_type: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        åœ¨ Chroma ä¸­è¿›è¡Œå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            node_type: å¯é€‰çš„èŠ‚ç‚¹ç±»å‹è¿‡æ»¤
        
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«èŠ‚ç‚¹ä¿¡æ¯å’Œç›¸ä¼¼åº¦
        """
        logger.info(f"æ‰§è¡Œå‘é‡æ£€ç´¢ï¼š'{query_text}'ï¼Œtop_k={top_k}")
        
        # æ‰§è¡Œæ£€ç´¢
        results = self.vectorstore.similarity_search_with_relevance_scores(
            query=query_text,
            k=top_k
        )
        
        # å¤„ç†æ£€ç´¢ç»“æœ
        search_results = []
        for doc, score in results:
            # ä»å…ƒæ•°æ®ä¸­æå–ä¿¡æ¯
            node_id = doc.metadata.get("node_id")
            node_type_val = doc.metadata.get("node_type")
            properties = doc.metadata.get("properties", {})
            
            # åº”ç”¨èŠ‚ç‚¹ç±»å‹è¿‡æ»¤
            if node_type and node_type_val != node_type:
                continue
            
            result = {
                "node_id": node_id,
                "node_type": node_type_val,
                "properties": properties,
                "distance": 1 - score,  # å°†ç›¸ä¼¼åº¦è½¬æ¢ä¸ºè·ç¦»ï¼ˆ1-ç›¸ä¼¼åº¦ï¼‰
                "similarity": score  # Chromaç›´æ¥æä¾›ç›¸ä¼¼åº¦
            }
            search_results.append(result)
        
        # æŒ‰è·ç¦»æ’åºå¹¶é™åˆ¶æ•°é‡
        search_results = sorted(search_results, key=lambda x: x["distance"])[:top_k]
        
        logger.info(f"å‘é‡æ£€ç´¢å®Œæˆï¼Œè¿”å› {len(search_results)} æ¡ç»“æœ")
        return search_results
    
    def expand_with_graph_relations(self, node_ids: List[int], relation_types: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """
        æ ¹æ®å›¾å…³ç³»æ‰©å±•èŠ‚ç‚¹ä¿¡æ¯
        
        Args:
            node_ids: æºèŠ‚ç‚¹ ID åˆ—è¡¨
            relation_types: å¯é€‰çš„å…³ç³»ç±»å‹è¿‡æ»¤
        
        Returns:
            æ‰©å±•åçš„å…³ç³»ä¿¡æ¯åˆ—è¡¨
        """
        logger.info(f"æ‰§è¡Œå›¾å…³ç³»æ‰©å±•ï¼šèŠ‚ç‚¹æ•°={len(node_ids)}")
        
        expanded_relations = []
        
        for node_id in node_ids:
            if node_id in self.relations_by_source:
                relations = self.relations_by_source[node_id]
                
                for rel in relations:
                    # å¦‚æœæŒ‡å®šäº†å…³ç³»ç±»å‹ï¼Œè¿›è¡Œè¿‡æ»¤
                    if relation_types and rel["relation_type"] not in relation_types:
                        continue
                    
                    # æ„å»ºæ‰©å±•å…³ç³»ä¿¡æ¯
                    expanded_rel = {
                        "source_id": rel["source_id"],
                        "target_id": rel["target_id"],
                        "relation_type": rel["relation_type"],
                        "properties": rel["properties"]
                    }
                    expanded_relations.append(expanded_rel)
        
        logger.info(f"å›¾å…³ç³»æ‰©å±•å®Œæˆï¼Œè¿”å› {len(expanded_relations)} æ¡å…³ç³»")
        return expanded_relations
    
    def get_target_node_info(self, target_ids: List[int]) -> Dict[int, Dict[str, Any]]:
        """
        æ ¹æ®ç›®æ ‡èŠ‚ç‚¹ ID è·å–èŠ‚ç‚¹ä¿¡æ¯
        
        Args:
            target_ids: ç›®æ ‡èŠ‚ç‚¹ ID åˆ—è¡¨
        
        Returns:
            èŠ‚ç‚¹ ID åˆ°èŠ‚ç‚¹ä¿¡æ¯çš„æ˜ å°„
        """
        if not target_ids:
            return {}
        
        # ä½¿ç”¨ Chroma çš„å‘é‡æ£€ç´¢æ¥æŸ¥æ‰¾ç‰¹å®šèŠ‚ç‚¹
        node_map = {}
        
        # é’ˆå¯¹æ¯ä¸ªç›®æ ‡IDæ„å»ºæŸ¥è¯¢
        for node_id in target_ids:
            # ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤æŸ¥è¯¢ç‰¹å®šnode_id
            results = self.vectorstore.similarity_search(
                query="",  # ç©ºæŸ¥è¯¢
                k=1,  # åªéœ€è¦ä¸€ä¸ªç»“æœ
                filter={"node_id": node_id}  # ç²¾ç¡®åŒ¹é…node_id
            )
            
            if results:
                doc = results[0]
                node_map[node_id] = {
                    "node_type": doc.metadata.get("node_type"),
                    "properties": doc.metadata.get("properties", {})
                }
        
        return node_map
    
    def query(self, question: str, top_k: int = 3, relation_types: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„ GraphRAG æŸ¥è¯¢
        1. å‘é‡æ£€ç´¢ç›¸å…³èŠ‚ç‚¹
        2. åŸºäºèŠ‚ç‚¹ ID æ‰©å±•å›¾å…³ç³»
        3. è·å–ç›®æ ‡èŠ‚ç‚¹ä¿¡æ¯
        4. æ•´åˆç»“æœ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            top_k: å‘é‡æ£€ç´¢è¿”å›çš„èŠ‚ç‚¹æ•°é‡
            relation_types: è¦æ‰©å±•çš„å…³ç³»ç±»å‹åˆ—è¡¨ï¼Œå¦‚ ["RECOMMEND_DRUG", "HAS_SYMPTOM"]
        
        Returns:
            æ•´åˆåçš„æŸ¥è¯¢ç»“æœ
        """
        logger.info(f"æ‰§è¡Œ GraphRAG æŸ¥è¯¢ï¼š'{question}'")
        
        # æ­¥éª¤1ï¼šå‘é‡æ£€ç´¢
        search_results = self.vector_search(question, top_k=top_k)
        
        # æå–æ£€ç´¢åˆ°çš„èŠ‚ç‚¹ ID
        retrieved_node_ids = [result["node_id"] for result in search_results]
        
        # æ­¥éª¤2ï¼šæ‰©å±•å›¾å…³ç³»
        expanded_relations = self.expand_with_graph_relations(retrieved_node_ids, relation_types)
        
        # æå–ç›®æ ‡èŠ‚ç‚¹ ID
        target_ids = list(set([rel["target_id"] for rel in expanded_relations]))
        
        # æ­¥éª¤3ï¼šè·å–ç›®æ ‡èŠ‚ç‚¹ä¿¡æ¯
        target_node_map = self.get_target_node_info(target_ids)
        
        # æ­¥éª¤4ï¼šæ•´åˆç»“æœ
        final_results = {
            "question": question,
            "retrieved_nodes": search_results,
            "relations": [
                {
                    "source_id": rel["source_id"],
                    "source_info": next((r for r in search_results if r["node_id"] == rel["source_id"]), None),
                    "relation_type": rel["relation_type"],
                    "target_id": rel["target_id"],
                    "target_info": target_node_map.get(rel["target_id"]),
                    "properties": rel["properties"]
                }
                for rel in expanded_relations
            ]
        }
        
        logger.info(f"GraphRAG æŸ¥è¯¢å®Œæˆï¼Œå‘ç° {len(expanded_relations)} æ¡ç›¸å…³å…³ç³»")
        return final_results
    
    def format_answer(self, results: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–æŸ¥è¯¢ç»“æœä¸ºå¯è¯»æ–‡æœ¬
        
        Args:
            results: GraphRAG æŸ¥è¯¢ç»“æœ
        
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬å›ç­”
        """
        parts = [f"é—®é¢˜: {results['question']}", "", "åŸºäºçŸ¥è¯†å›¾è°±çš„å›ç­”:", ""]
        
        # æ·»åŠ æ£€ç´¢åˆ°çš„èŠ‚ç‚¹ä¿¡æ¯
        if results['retrieved_nodes']:
            parts.append("ğŸ” æ£€ç´¢åˆ°çš„ç›¸å…³å®ä½“:")
            for node in results['retrieved_nodes']:
                node_name = node['properties'].get('name', 'æœªå‘½å')
                node_type = node['node_type']
                similarity = node['similarity']
                parts.append(f"  - [{node_type}] {node_name} (ç›¸å…³åº¦: {similarity:.3f})")
            parts.append("")
        
        # æ·»åŠ å…³ç³»ä¿¡æ¯
        if results['relations']:
            parts.append("ğŸ“Š çŸ¥è¯†å›¾è°±å…³ç³»:")
            
            # æŒ‰å…³ç³»ç±»å‹åˆ†ç»„
            relations_by_type = {}
            for rel in results['relations']:
                rel_type = rel['relation_type']
                if rel_type not in relations_by_type:
                    relations_by_type[rel_type] = []
                relations_by_type[rel_type].append(rel)
            
            # ä¸ºæ¯ç§å…³ç³»ç±»å‹ç”Ÿæˆæè¿°
            for rel_type, rels in relations_by_type.items():
                # æ˜ å°„å…³ç³»ç±»å‹åˆ°ä¸­æ–‡æè¿°
                rel_type_zh = {
                    "HAS_SYMPTOM": "ç—‡çŠ¶",
                    "RECOMMEND_DRUG": "æ¨èè¯ç‰©",
                    "NOT_EAT": "å¿Œå£",
                    "DO_EAT": "å®œåƒé£Ÿç‰©",
                    "ACOMPANY": "å¹¶å‘ç—‡"
                }.get(rel_type, rel_type)
                
                parts.append(f"\n  {rel_type_zh}:")
                
                # æŒ‰æºèŠ‚ç‚¹åˆ†ç»„
                source_relations = {}
                for rel in rels:
                    source_id = rel['source_id']
                    if source_id not in source_relations:
                        source_relations[source_id] = []
                    source_relations[source_id].append(rel)
                
                # ä¸ºæ¯ä¸ªæºèŠ‚ç‚¹ç”Ÿæˆæè¿°
                for source_id, source_rels in source_relations.items():
                    source_node = results['retrieved_nodes'][0]  # ç®€åŒ–å¤„ç†
                    source_name = source_node['properties'].get('name', 'æœªå‘½å')
                    
                    # æ”¶é›†ç›®æ ‡èŠ‚ç‚¹åç§°
                    target_names = []
                    for rel in source_rels:
                        if rel['target_info']:
                            target_name = rel['target_info']['properties'].get('name', 'æœªçŸ¥')
                            target_names.append(target_name)
                    
                    if target_names:
                        parts.append(f"    {source_name} â†’ {rel_type_zh}: {', '.join(target_names)}")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯
        if not results['retrieved_nodes'] and not results['relations']:
            parts.append("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œè¯·å°è¯•å…¶ä»–é—®é¢˜æˆ–æ£€æŸ¥çŸ¥è¯†å›¾è°±æ•°æ®ã€‚")
        
        return "\n".join(parts)
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        # Chroma ä¸éœ€è¦æ‰‹åŠ¨é‡Šæ”¾é›†åˆèµ„æº
        logger.info("GraphRAGQueryEngine èµ„æºå·²é‡Šæ”¾")


def main():
    """æ¼”ç¤º GraphRAG æŸ¥è¯¢å¼•æ“çš„ä½¿ç”¨"""
    print("ğŸ¤– GraphRAG æŸ¥è¯¢å¼•æ“æ¼”ç¤º")
    print("-------------------------")
    
    try:
        # åˆ›å»ºæŸ¥è¯¢å¼•æ“å®ä¾‹
        engine = GraphRAGQueryEngine()
        
        # ç¤ºä¾‹æŸ¥è¯¢1ï¼šæŸ¥è¯¢æ„Ÿå†’çš„ç—‡çŠ¶
        print("\nğŸ“ ç¤ºä¾‹1ï¼šæŸ¥è¯¢æ„Ÿå†’çš„ç—‡çŠ¶")
        results1 = engine.query(
            question="æ„Ÿå†’æœ‰å“ªäº›ç—‡çŠ¶ï¼Ÿ",
            top_k=2,
            relation_types=["HAS_SYMPTOM"]
        )
        print(engine.format_answer(results1))
        
        # ç¤ºä¾‹æŸ¥è¯¢2ï¼šæŸ¥è¯¢æ„Ÿå†’æ¨èè¯ç‰©
        print("\nğŸ“ ç¤ºä¾‹2ï¼šæŸ¥è¯¢æ„Ÿå†’æ¨èè¯ç‰©")
        results2 = engine.query(
            question="æ„Ÿå†’åº”è¯¥åƒä»€ä¹ˆè¯ï¼Ÿ",
            top_k=2,
            relation_types=["RECOMMEND_DRUG"]
        )
        print(engine.format_answer(results2))
        
        # ç¤ºä¾‹æŸ¥è¯¢3ï¼šç»¼åˆæŸ¥è¯¢
        print("\nğŸ“ ç¤ºä¾‹3ï¼šç»¼åˆæŸ¥è¯¢ï¼ˆç—‡çŠ¶å’Œå¿Œå£ï¼‰")
        results3 = engine.query(
            question="é«˜è¡€å‹çš„æ³¨æ„äº‹é¡¹",
            top_k=2,
            relation_types=["HAS_SYMPTOM", "NOT_EAT"]
        )
        print(engine.format_answer(results3))
        
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()